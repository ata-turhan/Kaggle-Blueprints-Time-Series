{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T14:00:49.091015Z",
     "iopub.status.busy": "2022-12-18T14:00:49.090158Z",
     "iopub.status.idle": "2022-12-18T14:01:02.815936Z",
     "shell.execute_reply": "2022-12-18T14:01:02.814971Z",
     "shell.execute_reply.started": "2022-12-18T14:00:49.090910Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import shap\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "customer = pd.read_csv(\"data/customer.csv\")\n",
    "customeraccount = pd.read_csv(\"data/customeraccount.csv\")\n",
    "genel_kategoriler = pd.read_csv(\"data/genel_kategoriler.csv\")\n",
    "product_groups = pd.read_csv(\"data/product_groups.csv\")\n",
    "transaction_header = pd.read_csv(\"data/transaction_header.csv\")\n",
    "transaction_sale = pd.read_csv(\"data/transaction_sale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = pd.merge(train, customer, how=\"left\")\n",
    "t_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genel_kategoriler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c_gk = pd.merge(t_c, genel_kategoriler, how=\"left\")\n",
    "t_c_gk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile25(data):\n",
    "    return data.quantile(0.25)\n",
    "def quantile75(data):\n",
    "    return data.quantile(0.75)\n",
    "\n",
    "aggregator_dict = {}\n",
    "for idx, val in enumerate(product_groups.columns[1:]):\n",
    "    aggregator_dict[val] = [\"min\", quantile25, \"median\", quantile75, \"max\", \"mean\", \"std\"]\n",
    "\n",
    "pg_grpd = product_groups.groupby('category_number')\n",
    "pg_grpd_agg = pg_grpd.agg(aggregator_dict)\n",
    "pg_grpd_agg = pg_grpd_agg.reset_index()\n",
    "pg_grpd_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for col in pg_grpd_agg.columns:\n",
    "    columns.append(\"-\".join(col))\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns[0] = columns[0][:-1]\n",
    "pg_grpd_agg.columns = columns\n",
    "pg_grpd_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c_gk_pg = pd.merge(t_c_gk, pg_grpd_agg, how = \"left\")\n",
    "t_c_gk_pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_th = pd.merge(customeraccount, transaction_header, how = \"left\")\n",
    "ca_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_th_ts = pd.merge(ca_th, transaction_sale, how = \"left\")\n",
    "ca_th_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator_dict = {}\n",
    "agg_cols = [\"is_sanal\", \"category_level_1\", \"category_level_2\", \"category_level_3\", \"category_level_4\",\n",
    "           \"amount\", \"quantity\", \"discount_type_1\", \"discount_type_2\", \"discount_type_3\"]\n",
    "for idx, val in enumerate(agg_cols):\n",
    "    aggregator_dict[val] = [\"min\", quantile25, \"median\", quantile75, \"max\", \"mean\", \"std\"]\n",
    "\n",
    "ca_th_ts_grpd = ca_th_ts.groupby('individualnumber')\n",
    "ca_th_ts_grpd_agg = ca_th_ts_grpd.agg(aggregator_dict)\n",
    "ca_th_ts_grpd_agg = ca_th_ts_grpd_agg.reset_index()\n",
    "ca_th_ts_grpd_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for col in ca_th_ts_grpd_agg.columns:\n",
    "    columns.append(\"_\".join(col))\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns[0] = columns[0][:-1]\n",
    "ca_th_ts_grpd_agg.columns = columns\n",
    "ca_th_ts_grpd_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(t_c_gk_pg, ca_th_ts_grpd_agg, how = \"left\", on = \"individualnumber\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([\"individualnumber\", \"response\"], axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"response\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[\"response\"].value_counts())\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"X.csv\", index=False)\n",
    "y.to_csv(\"y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"X.csv\")\n",
    "y = pd.read_csv(\"y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = LabelEncoder() \n",
    "X['gender'] = lbl.fit_transform(X['gender'].astype(str))\n",
    "X['genel_kategori'] = lbl.fit_transform(X['genel_kategori'].astype(str))  \n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "    lgbmc_base = LGBMClassifier()\n",
    "    lgbmc_base.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = lgbmc_base.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "    xgbc_base = XGBClassifier()\n",
    "    xgbc_base.fit(X_train, y_train)\n",
    "    y_pred = xgbc_base.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "    cb_base = CatBoostClassifier(verbose = 0)\n",
    "    cb_base.fit(X_train, y_train)\n",
    "    y_pred = cb_base.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'metric': 'mlogloss', \n",
    "        'n_estimators': trial.suggest_int('num_leaves', 1000, 10000),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.006,0.008,0.01,0.014,0.017,0.02]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [10,20,100]),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "        'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100),\n",
    "         \"scale_pos_weight\": trial.suggest_int('scale_pos_weight', 3, 10),\n",
    "    }\n",
    "        \n",
    "    f1_scores = []\n",
    "\n",
    "    for _ in range(5):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "        lgbmc = LGBMClassifier(**params)\n",
    "        lgbmc.fit(X_train, y_train.values.ravel())\n",
    "        y_pred = lgbmc.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "        \"scale_pos_weight\": trial.suggest_int('scale_pos_weight', 3, 10),\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'use_label_encoder': False\n",
    "    }\n",
    "        \n",
    "    f1_scores = []\n",
    "\n",
    "    for _ in range(5):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "        xgbc = XGBClassifier(**params)\n",
    "        xgbc.fit(X_train, y_train)\n",
    "        y_pred = xgbc.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 500, 5000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1, 100),\n",
    "        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 0.1, 20.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1.0, 2.0),\n",
    "        'depth': trial.suggest_int('depth', 1, 10),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 300),\n",
    "         \"scale_pos_weight\": trial.suggest_int('scale_pos_weight', 3, 10),\n",
    "        \"verbose\" : 0\n",
    "    }\n",
    "        \n",
    "    f1_scores = []\n",
    "\n",
    "    for _ in range(5):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "        cbc = CatBoostClassifier(**params)\n",
    "        cbc.fit(X_train, y_train)\n",
    "        y_pred = cbc.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgbc_final = XGBClassifier(**trial.params)\n",
    "xgbc_final.fit(X, y)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 24)\n",
    "plot_importance(xgbc_final)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainerxgbc = shap.TreeExplainer(xgbc_final)\n",
    "shap_values_XGBoost_train = explainerxgbc.shap_values(X)\n",
    "shap.summary_plot(shap_values_XGBoost_train, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE AND PREDICT TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_c = pd.merge(test, customer, how=\"left\")\n",
    "test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_c_gk = pd.merge(test_c, genel_kategoriler, how=\"left\")\n",
    "test_c_gk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_c_gk = pd.merge(test_c_gk, pg_grpd_agg, how = \"left\")\n",
    "test_c_gk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test_c_gk, ca_th_ts_grpd_agg, how = \"left\", on = \"individualnumber\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop([\"individualnumber\"], axis = 1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = LabelEncoder() \n",
    "X_test['gender'] = lbl.fit_transform(X_test['gender'].astype(str))\n",
    "X_test['genel_kategori'] = lbl.fit_transform(X_test['genel_kategori'].astype(str))  \n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = xgbc_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"individualnumber\":test[\"individualnumber\"]})\n",
    "submission['response'] = y_test_pred\n",
    "submission.response = submission.response.astype(int)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T14:03:54.735052Z",
     "iopub.status.busy": "2022-12-18T14:03:54.734536Z",
     "iopub.status.idle": "2022-12-18T14:03:54.762149Z",
     "shell.execute_reply": "2022-12-18T14:03:54.760831Z",
     "shell.execute_reply.started": "2022-12-18T14:03:54.735019Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f\"Submission-{time.strftime('%d - %H-%M-%S')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
